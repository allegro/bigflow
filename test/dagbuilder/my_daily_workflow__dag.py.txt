# This file was generated by `bigflow build-dags`
# bigflow-workflow:  	my_daily_workflow
# bigflow-build-ver: 	0.3.0
# bigflow-startdate: 	2020-07-02T00:00:00
# biglfow-imageid:   	eu.gcr.io/my_docker_repository_project/my-project:0.3.0

import datetime
from airflow import DAG

try:
    # For Airflow 2.x + Composer 2.x
    from airflow.kubernetes.secret import Secret
    from airflow.providers.cncf.kubernetes.operators.kubernetes_pod import KubernetesPodOperator
    IS_COMPOSER_2_X = True
except ImportError:
    # Fallback to Airflow 1.x + Composer 1.x
    from airflow.contrib.kubernetes.secret import Secret
    from airflow.contrib.operators.kubernetes_pod_operator import KubernetesPodOperator
    IS_COMPOSER_2_X = False

default_args = dict(
    owner='airflow',
    depends_on_past=True,
    start_date=datetime.datetime(2020, 7, 1, 0, 0),
    email_on_failure=False,
    email_on_retry=False,
    execution_timeout=datetime.timedelta(seconds=10800),
)

dag = DAG(
    'my_daily_workflow__v0_3_0__2020_07_02_00_00_00',
    default_args=default_args,
    max_active_runs=1,
    schedule_interval='@daily',
)

tjob1 = KubernetesPodOperator(
    dag=dag,
    task_id='job1',
    name='job1',
    cmds=['python', '-m', 'bigflow', 'run'],
    arguments=[
        '--job', 'my_daily_workflow.job1',
        '--runtime', '{{ execution_date.strftime("%Y-%m-%d %H:%M:%S") }}',
        '--project-package', 'ca',
        '--config', '{{var.value.env}}',
    ],
    namespace='composer-user-workloads' if IS_COMPOSER_2_X else 'default',
    image='eu.gcr.io/my_docker_repository_project/my-project:0.3.0',
    is_delete_operator_pod=True,
    retries=10,
    retry_delay=datetime.timedelta(seconds=20),
    secrets=[],
    execution_timeout=datetime.timedelta(seconds=10800),
)


